//
// Generated by LLVM NVPTX Back-End
//

.version 6.1
.target sm_60
.address_size 64

	// .weak	__omp_offloading_10302_a18a2_axpy_l12
.func __omp_outlined__
(
	.param .b64 __omp_outlined___param_0,
	.param .b64 __omp_outlined___param_1,
	.param .b64 __omp_outlined___param_2,
	.param .b64 __omp_outlined___param_3,
	.param .b64 __omp_outlined___param_4,
	.param .b64 __omp_outlined___param_5
)
;
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.func __kmpc_for_static_init_4
(
	.param .b64 __kmpc_for_static_init_4_param_0,
	.param .b32 __kmpc_for_static_init_4_param_1,
	.param .b32 __kmpc_for_static_init_4_param_2,
	.param .b64 __kmpc_for_static_init_4_param_3,
	.param .b64 __kmpc_for_static_init_4_param_4,
	.param .b64 __kmpc_for_static_init_4_param_5,
	.param .b64 __kmpc_for_static_init_4_param_6,
	.param .b32 __kmpc_for_static_init_4_param_7,
	.param .b32 __kmpc_for_static_init_4_param_8
)
;
.func __kmpc_for_static_fini
(
	.param .b64 __kmpc_for_static_fini_param_0,
	.param .b32 __kmpc_for_static_fini_param_1
)
;
.func __kmpc_spmd_kernel_init
(
	.param .b32 __kmpc_spmd_kernel_init_param_0,
	.param .b32 __kmpc_spmd_kernel_init_param_1,
	.param .b32 __kmpc_spmd_kernel_init_param_2
)
;
.func  (.param .b32 func_retval0) _ZL9atomicAddPjj7
(
	.param .b64 _ZL9atomicAddPjj7_param_0,
	.param .b32 _ZL9atomicAddPjj7_param_1
)
;
.func  (.param .b64 func_retval0) _ZL9atomicAddPyy8
(
	.param .b64 _ZL9atomicAddPyy8_param_0
)
;
.func _ZL10atomicExchPjj9
(
	.param .b64 _ZL10atomicExchPjj9_param_0,
	.param .b32 _ZL10atomicExchPjj9_param_1
)
;
.func __kmpc_spmd_kernel_deinit_v2
(
	.param .b32 __kmpc_spmd_kernel_deinit_v2_param_0
)
;
.func _ZL10atomicExchPyy
(
	.param .b64 _ZL10atomicExchPyy_param_0,
	.param .b64 _ZL10atomicExchPyy_param_1
)
;
.func  (.param .b32 func_retval0) __kmpc_global_thread_num
(
	.param .b64 __kmpc_global_thread_num_param_0
)
;
.shared .align 8 .u64 _openmp_kernel_static_glob_rd$ptr;
.global .align 1 .b8 _$_str[23] = {59, 117, 110, 107, 110, 111, 119, 110, 59, 117, 110, 107, 110, 111, 119, 110, 59, 48, 59, 48, 59, 59, 0};
.global .align 8 .u64 __unnamed_1[3] = {2207613190144, 3, generic(_$_str)};
.global .align 1 .b8 _$_str1[20] = {116, 104, 105, 115, 32, 97, 32, 116, 115, 101, 116, 58, 32, 37, 102, 32, 37, 102, 10, 0};
.global .align 8 .u64 __unnamed_2[3] = {8589934592, 3, generic(_$_str)};
.weak .global .align 1 .u8 __omp_offloading_10302_a18a2_axpy_l12_exec_mode;
.extern .shared .align 4 .u32 execution_param;
.extern .shared .align 1 .b8 parallelLevel[32];
.extern .shared .align 2 .u16 threadsInTeam;
.extern .shared .align 4 .u32 usedSlotIdx;
.extern .global .align 16 .b8 omptarget_nvptx_device_State[674273152];
.extern .shared .align 8 .b64 omptarget_nvptx_threadPrivateContext;
.extern .shared .align 8 .b8 DataSharingState[896];

.weak .entry __omp_offloading_10302_a18a2_axpy_l12(
	.param .u64 __omp_offloading_10302_a18a2_axpy_l12_param_0,
	.param .u64 __omp_offloading_10302_a18a2_axpy_l12_param_1,
	.param .u64 __omp_offloading_10302_a18a2_axpy_l12_param_2,
	.param .u64 __omp_offloading_10302_a18a2_axpy_l12_param_3
)
{
	.local .align 8 .b8 	__local_depot0[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<17>;

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd6, [__omp_offloading_10302_a18a2_axpy_l12_param_3];
	ld.param.u64 	%rd5, [__omp_offloading_10302_a18a2_axpy_l12_param_2];
	ld.param.u64 	%rd4, [__omp_offloading_10302_a18a2_axpy_l12_param_1];
	ld.param.u64 	%rd3, [__omp_offloading_10302_a18a2_axpy_l12_param_0];
	cvta.to.global.u64 	%rd7, %rd6;
	cvta.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.global.u64 	%rd10, %rd9;
	mov.u32 	%r1, 0;
	st.u32 	[%SP+40], %r1;
	st.u32 	[%SP+32], %r1;
	st.u64 	[%SP+0], %rd3;
	st.u64 	[%SP+8], %rd10;
	st.u64 	[%SP+16], %rd5;
	st.u64 	[%SP+24], %rd8;
	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SP, 16;
	mov.u32 	%r2, %ntid.x;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r2;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r1;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r1;
	call.uni 
	__kmpc_spmd_kernel_init, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 0
	bra.uni 	LBB0_1;
LBB0_1:
	mov.u64 	%rd11, __unnamed_2;
	cvta.global.u64 	%rd12, %rd11;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd12;
	.param .b32 retval0;
	call.uni (retval0), 
	__kmpc_global_thread_num, 
	(
	param0
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 1
	st.u32 	[%SP+36], %r3;
	add.u64 	%rd13, %SP, 36;
	add.u64 	%rd14, %SP, 40;
	add.u64 	%rd15, %SP, 8;
	add.u64 	%rd16, %SP, 24;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd14;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd15;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd2;
	.param .b64 param5;
	st.param.b64 	[param5+0], %rd16;
	call.uni 
	__omp_outlined__, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5
	);
	} // callseq 2
	bra.uni 	LBB0_2;
LBB0_2:
	mov.u32 	%r5, 0;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r5;
	call.uni 
	__kmpc_spmd_kernel_deinit_v2, 
	(
	param0
	);
	} // callseq 3
	bra.uni 	LBB0_3;
LBB0_3:
	ret;

}
.func __omp_outlined__(
	.param .b64 __omp_outlined___param_0,
	.param .b64 __omp_outlined___param_1,
	.param .b64 __omp_outlined___param_2,
	.param .b64 __omp_outlined___param_3,
	.param .b64 __omp_outlined___param_4,
	.param .b64 __omp_outlined___param_5
)
{
	.local .align 8 .b8 	__local_depot1[104];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .f32 	%f<8>;
	.reg .b32 	%r<34>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<36>;

	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd9, [__omp_outlined___param_5];
	ld.param.u64 	%rd8, [__omp_outlined___param_4];
	ld.param.u64 	%rd7, [__omp_outlined___param_3];
	ld.param.u64 	%rd6, [__omp_outlined___param_2];
	ld.param.u64 	%rd5, [__omp_outlined___param_1];
	ld.param.u64 	%rd4, [__omp_outlined___param_0];
	st.u64 	[%SP+0], %rd4;
	st.u64 	[%SP+8], %rd5;
	st.u64 	[%SP+16], %rd6;
	st.u64 	[%SP+24], %rd7;
	st.u64 	[%SP+32], %rd8;
	st.u64 	[%SP+40], %rd9;
	ld.u64 	%rd10, [%SP+16];
	ld.u64 	%rd1, [%SP+24];
	ld.u64 	%rd2, [%SP+32];
	ld.u64 	%rd3, [%SP+40];
	ld.u32 	%r4, [%rd10];
	st.u32 	[%SP+56], %r4;
	ld.u32 	%r5, [%SP+56];
	add.s32 	%r6, %r5, -1;
	st.u32 	[%SP+60], %r6;
	mov.u32 	%r7, 0;
	st.u32 	[%SP+64], %r7;
	ld.u32 	%r8, [%SP+56];
	setp.lt.s32 	%p1, %r8, 1;
	@%p1 bra 	LBB1_14;
	bra.uni 	LBB1_1;
LBB1_1:
	mov.u32 	%r9, 0;
	st.u32 	[%SP+68], %r9;
	ld.u32 	%r10, [%SP+60];
	st.u32 	[%SP+72], %r10;
	mov.u32 	%r11, 1;
	st.u32 	[%SP+76], %r11;
	st.u32 	[%SP+80], %r9;
	ld.u64 	%rd11, [%SP+0];
	ld.u32 	%r12, [%rd11];
	mov.u64 	%rd12, __unnamed_1;
	cvta.global.u64 	%rd13, %rd12;
	mov.u32 	%r13, 33;
	add.u64 	%rd14, %SP, 80;
	add.u64 	%rd15, %SP, 68;
	add.u64 	%rd16, %SP, 72;
	add.u64 	%rd17, %SP, 76;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r12;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r13;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd14;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd15;
	.param .b64 param5;
	st.param.b64 	[param5+0], %rd16;
	.param .b64 param6;
	st.param.b64 	[param6+0], %rd17;
	.param .b32 param7;
	st.param.b32 	[param7+0], %r11;
	.param .b32 param8;
	st.param.b32 	[param8+0], %r11;
	call.uni 
	__kmpc_for_static_init_4, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5, 
	param6, 
	param7, 
	param8
	);
	} // callseq 4
	bra.uni 	LBB1_2;
LBB1_2:
	ld.u32 	%r14, [%SP+72];
	ld.u32 	%r15, [%SP+60];
	setp.le.s32 	%p2, %r14, %r15;
	@%p2 bra 	LBB1_4;
	bra.uni 	LBB1_3;
LBB1_3:
	ld.u32 	%r1, [%SP+60];
	mov.u32 	%r33, %r1;
	bra.uni 	LBB1_5;
LBB1_4:
	ld.u32 	%r2, [%SP+72];
	mov.u32 	%r33, %r2;
	bra.uni 	LBB1_5;
LBB1_5:
	mov.u32 	%r3, %r33;
	st.u32 	[%SP+72], %r3;
	ld.u32 	%r16, [%SP+68];
	st.u32 	[%SP+48], %r16;
	ld.u32 	%r17, [%SP+48];
	ld.u32 	%r18, [%SP+72];
	setp.gt.s32 	%p3, %r17, %r18;
	@%p3 bra 	LBB1_13;
	bra.uni 	LBB1_6;
LBB1_6:
	bra.uni 	LBB1_7;
LBB1_7:
	ld.u32 	%r20, [%SP+48];
	ld.u32 	%r21, [%SP+72];
	setp.gt.s32 	%p4, %r20, %r21;
	@%p4 bra 	LBB1_11;
	bra.uni 	LBB1_8;
LBB1_8:
	ld.u32 	%r28, [%SP+48];
	st.u32 	[%SP+84], %r28;
	ld.f32 	%f1, [%rd2];
	ld.u64 	%rd21, [%rd3];
	ld.s32 	%rd22, [%SP+84];
	shl.b64 	%rd23, %rd22, 2;
	add.s64 	%rd24, %rd21, %rd23;
	ld.f32 	%f2, [%rd24];
	mul.rn.f32 	%f3, %f1, %f2;
	ld.u64 	%rd25, [%rd1];
	add.s64 	%rd26, %rd25, %rd23;
	ld.f32 	%f4, [%rd26];
	add.rn.f32 	%f5, %f4, %f3;
	st.f32 	[%rd26], %f5;
	ld.u64 	%rd27, [%rd3];
	ld.s32 	%rd28, [%SP+84];
	shl.b64 	%rd29, %rd28, 2;
	add.s64 	%rd30, %rd27, %rd29;
	ld.f32 	%f6, [%rd30];
	cvt.f64.f32 	%fd1, %f6;
	ld.u64 	%rd31, [%rd1];
	add.s64 	%rd32, %rd31, %rd29;
	ld.f32 	%f7, [%rd32];
	cvt.f64.f32 	%fd2, %f7;
	st.f64 	[%SP+88], %fd1;
	st.f64 	[%SP+96], %fd2;
	mov.u64 	%rd33, _$_str1;
	cvta.global.u64 	%rd34, %rd33;
	add.u64 	%rd35, %SP, 88;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r29, [retval0+0];
	} // callseq 6
	bra.uni 	LBB1_9;
LBB1_9:
	bra.uni 	LBB1_10;
LBB1_10:
	ld.u32 	%r31, [%SP+48];
	add.s32 	%r32, %r31, 1;
	st.u32 	[%SP+48], %r32;
	bra.uni 	LBB1_7;
LBB1_11:
	bra.uni 	LBB1_12;
LBB1_12:
	ld.u32 	%r22, [%SP+68];
	ld.u32 	%r23, [%SP+76];
	add.s32 	%r24, %r22, %r23;
	st.u32 	[%SP+68], %r24;
	ld.u32 	%r25, [%SP+72];
	ld.u32 	%r26, [%SP+76];
	add.s32 	%r27, %r25, %r26;
	st.u32 	[%SP+72], %r27;
	bra.uni 	LBB1_2;
LBB1_13:
	ld.u64 	%rd18, [%SP+0];
	ld.u32 	%r19, [%rd18];
	mov.u64 	%rd19, __unnamed_1;
	cvta.global.u64 	%rd20, %rd19;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd20;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r19;
	call.uni 
	__kmpc_for_static_fini, 
	(
	param0, 
	param1
	);
	} // callseq 5
	bra.uni 	LBB1_14;
LBB1_14:
	ret;

}
.func __kmpc_for_static_init_4(
	.param .b64 __kmpc_for_static_init_4_param_0,
	.param .b32 __kmpc_for_static_init_4_param_1,
	.param .b32 __kmpc_for_static_init_4_param_2,
	.param .b64 __kmpc_for_static_init_4_param_3,
	.param .b64 __kmpc_for_static_init_4_param_4,
	.param .b64 __kmpc_for_static_init_4_param_5,
	.param .b64 __kmpc_for_static_init_4_param_6,
	.param .b32 __kmpc_for_static_init_4_param_7,
	.param .b32 __kmpc_for_static_init_4_param_8
)
{
	.reg .pred 	%p<37>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<124>;
	.reg .b64 	%rd<16>;

	ld.param.u32 	%r46, [__kmpc_for_static_init_4_param_8];
	ld.param.u64 	%rd5, [__kmpc_for_static_init_4_param_6];
	ld.param.u64 	%rd4, [__kmpc_for_static_init_4_param_5];
	ld.param.u64 	%rd3, [__kmpc_for_static_init_4_param_4];
	ld.param.u64 	%rd2, [__kmpc_for_static_init_4_param_3];
	ld.param.u32 	%r45, [__kmpc_for_static_init_4_param_2];
	ld.param.u32 	%r44, [__kmpc_for_static_init_4_param_1];
	ld.param.u64 	%rd1, [__kmpc_for_static_init_4_param_0];
	setp.ne.s64 	%p12, %rd1, 0;
	@%p12 bra 	LBB2_2;
	bra.uni 	LBB2_1;
LBB2_1:
	mov.u64 	%rd8, execution_param;
	cvta.shared.u64 	%rd9, %rd8;
	ld.u32 	%r51, [%rd9];
	and.b32  	%r52, %r51, 1;
	setp.eq.b32 	%p1, %r52, 1;
	mov.pred 	%p35, %p1;
	bra.uni 	LBB2_5;
LBB2_2:
	ld.u32 	%r1, [%rd1+8];
	and.b32  	%r47, %r1, 1;
	setp.eq.b32 	%p14, %r47, 1;
	mov.pred 	%p15, 0;
	xor.pred  	%p16, %p14, %p15;
	mov.pred 	%p13, -1;
	mov.pred 	%p35, %p13;
	@%p16 bra 	LBB2_5;
	bra.uni 	LBB2_3;
LBB2_3:
	and.b32  	%r48, %r1, 2;
	setp.eq.s32 	%p18, %r48, 0;
	mov.pred 	%p17, 0;
	mov.pred 	%p35, %p17;
	@%p18 bra 	LBB2_5;
	bra.uni 	LBB2_4;
LBB2_4:
	mov.u64 	%rd6, execution_param;
	cvta.shared.u64 	%rd7, %rd6;
	ld.u32 	%r49, [%rd7];
	and.b32  	%r50, %r49, 1;
	setp.eq.b32 	%p2, %r50, 1;
	mov.pred 	%p35, %p2;
	bra.uni 	LBB2_5;
LBB2_5:
	mov.pred 	%p3, %p35;
	mov.u32 	%r54, %tid.x;
	shr.u32 	%r55, %r54, 5;
	cvt.u64.u32 	%rd10, %r55;
	mov.u64 	%rd11, parallelLevel;
	add.s64 	%rd12, %rd11, %rd10;
	cvta.shared.u64 	%rd13, %rd12;
	ld.u8 	%rs1, [%rd13];
	setp.ne.s16 	%p19, %rs1, 129;
	mov.u32 	%r53, 1;
	mov.u32 	%r116, %r53;
	@%p19 bra 	LBB2_9;
	bra.uni 	LBB2_6;
LBB2_6:
	@!%p3 bra 	LBB2_8;
	bra.uni 	LBB2_7;
LBB2_7:
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r116, %r2;
	bra.uni 	LBB2_9;
LBB2_8:
	mov.u64 	%rd14, threadsInTeam;
	cvta.shared.u64 	%rd15, %rd14;
	ld.u16 	%r3, [%rd15];
	mov.u32 	%r116, %r3;
	bra.uni 	LBB2_9;
LBB2_9:
	mov.u32 	%r4, %r116;
	ld.u32 	%r5, [%rd3];
	ld.u32 	%r6, [%rd4];
	and.b32  	%r56, %r45, -1610612737;
	setp.eq.s32 	%p20, %r56, 33;
	@%p20 bra 	LBB2_10;
	bra.uni 	LBB2_27;
LBB2_27:
	setp.eq.s32 	%p21, %r56, 34;
	@%p21 bra 	LBB2_14;
	bra.uni 	LBB2_28;
LBB2_28:
	setp.eq.s32 	%p22, %r56, 45;
	@%p22 bra 	LBB2_12;
	bra.uni 	LBB2_29;
LBB2_29:
	setp.eq.s32 	%p23, %r56, 91;
	@%p23 bra 	LBB2_18;
	bra.uni 	LBB2_30;
LBB2_30:
	setp.eq.s32 	%p24, %r56, 92;
	@%p24 bra 	LBB2_20;
	bra.uni 	LBB2_31;
LBB2_31:
	setp.eq.s32 	%p25, %r56, 93;
	@%p25 bra 	LBB2_24;
	bra.uni 	LBB2_25;
LBB2_10:
	setp.lt.s32 	%p31, %r46, 1;
	@%p31 bra 	LBB2_14;
	bra.uni 	LBB2_11;
LBB2_11:
	mul.lo.s32 	%r7, %r4, %r46;
	mul.lo.s32 	%r103, %r46, %r44;
	add.s32 	%r8, %r5, %r103;
	add.s32 	%r104, %r46, %r8;
	add.s32 	%r9, %r104, -1;
	rem.s32 	%r105, %r6, %r46;
	sub.s32 	%r106, %r6, %r8;
	sub.s32 	%r107, %r106, %r105;
	rem.s32 	%r108, %r107, %r7;
	setp.eq.s32 	%p4, %r108, 0;
	mov.pred 	%p36, %p4;
	mov.u32 	%r121, %r8;
	mov.u32 	%r122, %r9;
	mov.u32 	%r123, %r7;
	bra.uni 	LBB2_26;
LBB2_12:
	setp.lt.s32 	%p30, %r46, 1;
	@%p30 bra 	LBB2_14;
	bra.uni 	LBB2_13;
LBB2_13:
	sub.s32 	%r83, %r4, %r5;
	add.s32 	%r84, %r83, %r6;
	div.s32 	%r85, %r84, %r4;
	add.s32 	%r86, %r46, %r85;
	add.s32 	%r87, %r86, -1;
	neg.s32 	%r88, %r46;
	and.b32  	%r89, %r87, %r88;
	mul.lo.s32 	%r10, %r89, %r4;
	mul.lo.s32 	%r90, %r89, %r44;
	add.s32 	%r11, %r90, %r5;
	add.s32 	%r91, %r89, %r11;
	add.s32 	%r92, %r91, -1;
	rem.s32 	%r93, %r6, %r89;
	sub.s32 	%r94, %r6, %r93;
	sub.s32 	%r95, %r94, %r11;
	rem.s32 	%r96, %r95, %r10;
	setp.eq.s32 	%p5, %r96, 0;
	min.s32 	%r12, %r92, %r6;
	mov.pred 	%p36, %p5;
	mov.u32 	%r121, %r11;
	mov.u32 	%r122, %r12;
	mov.u32 	%r123, %r10;
	bra.uni 	LBB2_26;
LBB2_14:
	sub.s32 	%r97, %r6, %r5;
	add.s32 	%r13, %r97, 1;
	div.s32 	%r14, %r13, %r4;
	mul.lo.s32 	%r98, %r14, %r4;
	sub.s32 	%r15, %r13, %r98;
	setp.le.s32 	%p32, %r15, %r44;
	@%p32 bra 	LBB2_16;
	bra.uni 	LBB2_15;
LBB2_15:
	add.s32 	%r16, %r14, 1;
	mul.lo.s32 	%r101, %r16, %r44;
	add.s32 	%r17, %r101, %r5;
	mov.u32 	%r117, %r16;
	mov.u32 	%r118, %r17;
	bra.uni 	LBB2_17;
LBB2_16:
	mul.lo.s32 	%r99, %r14, %r44;
	add.s32 	%r100, %r99, %r5;
	add.s32 	%r18, %r100, %r15;
	mov.u32 	%r117, %r14;
	mov.u32 	%r118, %r18;
	bra.uni 	LBB2_17;
LBB2_17:
	mov.u32 	%r20, %r118;
	mov.u32 	%r19, %r117;
	add.s32 	%r102, %r20, %r19;
	add.s32 	%r21, %r102, -1;
	setp.le.s32 	%p33, %r20, %r6;
	setp.lt.s32 	%p34, %r6, %r102;
	and.pred  	%p6, %p33, %p34;
	mov.pred 	%p36, %p6;
	mov.u32 	%r121, %r20;
	mov.u32 	%r122, %r21;
	mov.u32 	%r123, %r13;
	bra.uni 	LBB2_26;
LBB2_18:
	setp.lt.s32 	%p26, %r46, 1;
	@%p26 bra 	LBB2_20;
	bra.uni 	LBB2_19;
LBB2_19:
	mov.u32 	%r75, %ctaid.x;
	mov.u32 	%r76, %nctaid.x;
	mul.lo.s32 	%r22, %r76, %r46;
	mul.lo.s32 	%r77, %r75, %r46;
	add.s32 	%r23, %r77, %r5;
	add.s32 	%r78, %r46, %r23;
	add.s32 	%r24, %r78, -1;
	rem.s32 	%r79, %r6, %r46;
	sub.s32 	%r80, %r6, %r79;
	sub.s32 	%r81, %r80, %r23;
	rem.s32 	%r82, %r81, %r22;
	setp.eq.s32 	%p7, %r82, 0;
	mov.pred 	%p36, %p7;
	mov.u32 	%r121, %r23;
	mov.u32 	%r122, %r24;
	mov.u32 	%r123, %r22;
	bra.uni 	LBB2_26;
LBB2_20:
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r68, %nctaid.x;
	sub.s32 	%r69, %r6, %r5;
	add.s32 	%r26, %r69, 1;
	div.s32 	%r27, %r26, %r68;
	mul.lo.s32 	%r70, %r27, %r68;
	sub.s32 	%r28, %r26, %r70;
	setp.le.s32 	%p27, %r28, %r25;
	@%p27 bra 	LBB2_22;
	bra.uni 	LBB2_21;
LBB2_21:
	add.s32 	%r29, %r27, 1;
	mul.lo.s32 	%r73, %r29, %r25;
	add.s32 	%r30, %r73, %r5;
	mov.u32 	%r119, %r29;
	mov.u32 	%r120, %r30;
	bra.uni 	LBB2_23;
LBB2_22:
	mul.lo.s32 	%r71, %r27, %r25;
	add.s32 	%r72, %r71, %r5;
	add.s32 	%r31, %r72, %r28;
	mov.u32 	%r119, %r27;
	mov.u32 	%r120, %r31;
	bra.uni 	LBB2_23;
LBB2_23:
	mov.u32 	%r33, %r120;
	mov.u32 	%r32, %r119;
	add.s32 	%r74, %r33, %r32;
	add.s32 	%r34, %r74, -1;
	setp.le.s32 	%p28, %r33, %r6;
	setp.lt.s32 	%p29, %r6, %r74;
	and.pred  	%p8, %p28, %p29;
	mov.pred 	%p36, %p8;
	mov.u32 	%r121, %r33;
	mov.u32 	%r122, %r34;
	mov.u32 	%r123, %r26;
	bra.uni 	LBB2_26;
LBB2_24:
	mov.u32 	%r57, %ctaid.x;
	mul.lo.s32 	%r58, %r57, %r4;
	add.s32 	%r59, %r58, %r44;
	mov.u32 	%r60, %nctaid.x;
	mul.lo.s32 	%r61, %r4, %r46;
	mul.lo.s32 	%r35, %r61, %r60;
	mul.lo.s32 	%r62, %r59, %r46;
	add.s32 	%r36, %r62, %r5;
	add.s32 	%r63, %r46, %r36;
	add.s32 	%r37, %r63, -1;
	rem.s32 	%r64, %r6, %r46;
	sub.s32 	%r65, %r6, %r64;
	sub.s32 	%r66, %r65, %r36;
	rem.s32 	%r67, %r66, %r35;
	setp.eq.s32 	%p9, %r67, 0;
	mov.pred 	%p36, %p9;
	mov.u32 	%r121, %r36;
	mov.u32 	%r122, %r37;
	mov.u32 	%r123, %r35;
	bra.uni 	LBB2_26;
LBB2_25:
	mul.lo.s32 	%r38, %r4, %r46;
	mul.lo.s32 	%r109, %r46, %r44;
	add.s32 	%r39, %r5, %r109;
	add.s32 	%r110, %r46, %r39;
	add.s32 	%r40, %r110, -1;
	rem.s32 	%r111, %r6, %r46;
	sub.s32 	%r112, %r6, %r39;
	sub.s32 	%r113, %r112, %r111;
	rem.s32 	%r114, %r113, %r38;
	setp.eq.s32 	%p10, %r114, 0;
	mov.pred 	%p36, %p10;
	mov.u32 	%r121, %r39;
	mov.u32 	%r122, %r40;
	mov.u32 	%r123, %r38;
	bra.uni 	LBB2_26;
LBB2_26:
	mov.u32 	%r43, %r123;
	mov.u32 	%r42, %r122;
	mov.u32 	%r41, %r121;
	mov.pred 	%p11, %p36;
	selp.u32 	%r115, 1, 0, %p11;
	st.u32 	[%rd2], %r115;
	st.u32 	[%rd3], %r41;
	st.u32 	[%rd4], %r42;
	st.u32 	[%rd5], %r43;
	ret;

}
.func __kmpc_for_static_fini(
	.param .b64 __kmpc_for_static_fini_param_0,
	.param .b32 __kmpc_for_static_fini_param_1
)
{


	ret;

}
.func __kmpc_spmd_kernel_init(
	.param .b32 __kmpc_spmd_kernel_init_param_0,
	.param .b32 __kmpc_spmd_kernel_init_param_1,
	.param .b32 __kmpc_spmd_kernel_init_param_2
)
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<77>;

	ld.param.u16 	%rs2, [__kmpc_spmd_kernel_init_param_2];
	ld.param.u16 	%rs1, [__kmpc_spmd_kernel_init_param_1];
	setp.ne.s16 	%p1, %rs1, 0;
	selp.b32 	%r4, 1, 3, %p1;
	mov.u64 	%rd17, execution_param;
	cvta.shared.u64 	%rd18, %rd17;
	st.u32 	[%rd18], %r4;
	mov.u32 	%r1, %tid.x;
	setp.eq.s32 	%p2, %r1, 0;
	setp.ne.s32 	%p3, %r1, 0;
	@%p3 bra 	LBB4_2;
	bra.uni 	LBB4_1;
LBB4_1:
	// begin inline asm
	mov.u32 %r7, %smid;
	// end inline asm
	shr.u32 	%r8, %r7, 3;
	cvt.u64.u32 	%rd23, %r8;
	mul.lo.s64 	%rd24, %rd23, 613566757;
	shr.u64 	%rd25, %rd24, 32;
	cvt.u32.u64 	%r9, %rd25;
	mul.lo.s32 	%r10, %r9, 56;
	sub.s32 	%r11, %r7, %r10;
	mov.u64 	%rd26, usedSlotIdx;
	cvta.shared.u64 	%rd27, %rd26;
	st.u32 	[%rd27], %r11;
	mov.u64 	%rd28, parallelLevel;
	cvta.shared.u64 	%rd22, %rd28;
	mov.u64 	%rd75, %rd22;
	bra.uni 	LBB4_4;
LBB4_2:
	and.b32  	%r5, %r1, 31;
	setp.ne.s32 	%p4, %r5, 0;
	@%p4 bra 	LBB4_5;
	bra.uni 	LBB4_3;
LBB4_3:
	shr.u32 	%r6, %r1, 5;
	cvt.u64.u32 	%rd19, %r6;
	mov.u64 	%rd20, parallelLevel;
	add.s64 	%rd21, %rd20, %rd19;
	cvta.shared.u64 	%rd1, %rd21;
	mov.u64 	%rd75, %rd1;
	bra.uni 	LBB4_4;
LBB4_4:
	mov.u64 	%rd2, %rd75;
	mov.u32 	%r12, %ntid.x;
	setp.gt.u32 	%p5, %r12, 1;
	selp.b16 	%rs3, -127, 1, %p5;
	st.u8 	[%rd2], %rs3;
	bra.uni 	LBB4_5;
LBB4_5:
	@%p1 bra 	LBB4_7;
	bra.uni 	LBB4_6;
LBB4_6:
	bar.sync 	0;
	bra.uni 	LBB4_18;
LBB4_7:
	@!%p2 bra 	LBB4_11;
	bra.uni 	LBB4_8;
LBB4_8:
	mov.u64 	%rd29, usedSlotIdx;
	cvta.shared.u64 	%rd30, %rd29;
	ld.u32 	%rd31, [%rd30];
	mul.lo.s64 	%rd32, %rd31, 12040592;
	mov.u64 	%rd33, omptarget_nvptx_device_State;
	add.s64 	%rd34, %rd33, %rd32;
	cvta.global.u64 	%rd3, %rd34;
	add.s64 	%rd35, %rd3, 12040448;
	mov.u32 	%r13, 1;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r13;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL9atomicAddPjj7, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r14, [retval0+0];
	} // callseq 7
	and.b32  	%r16, %r14, 31;
	shr.u32 	%r17, %r14, 4;
	and.b32  	%r2, %r17, 268435454;
	cvt.u64.u32 	%rd4, %r16;
	shl.b64 	%rd36, %rd4, 2;
	add.s64 	%rd37, %rd3, %rd36;
	add.s64 	%rd5, %rd37, 12040452;
	bra.uni 	LBB4_9;
LBB4_9:
	mov.u32 	%r18, 0;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd5;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r18;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL9atomicAddPjj7, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r19, [retval0+0];
	} // callseq 8
	setp.ne.s32 	%p6, %r19, %r2;
	@%p6 bra 	LBB4_9;
	bra.uni 	LBB4_10;
LBB4_10:
	shl.b64 	%rd38, %rd4, 3;
	add.s64 	%rd39, %rd3, %rd38;
	add.s64 	%rd40, %rd39, 12040192;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	_ZL9atomicAddPyy8, 
	(
	param0
	);
	ld.param.b64 	%rd41, [retval0+0];
	} // callseq 9
	setp.eq.s64 	%p7, %rd41, 0;
	mul.lo.s64 	%rd43, %rd4, 376256;
	add.s64 	%rd44, %rd3, %rd43;
	selp.b64 	%rd45, %rd44, %rd41, %p7;
	and.b32  	%r21, %r2, 33554430;
	or.b32  	%r22, %r21, 1;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd5;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r22;
	call.uni 
	_ZL10atomicExchPjj9, 
	(
	param0, 
	param1
	);
	} // callseq 10
	mov.u64 	%rd46, omptarget_nvptx_threadPrivateContext;
	cvta.shared.u64 	%rd47, %rd46;
	st.u64 	[%rd47], %rd45;
	mov.u16 	%rs4, 0;
	st.u8 	[%rd45+40], %rs4;
	st.u16 	[%rd45+42], %rs4;
	mov.u64 	%rd48, 1;
	st.u64 	[%rd45+48], %rd48;
	bra.uni 	LBB4_11;
LBB4_11:
	bar.sync 	0;
	mov.u64 	%rd49, omptarget_nvptx_threadPrivateContext;
	cvta.shared.u64 	%rd50, %rd49;
	ld.u64 	%rd6, [%rd50];
	cvt.u64.u32 	%rd51, %r1;
	shl.b64 	%rd52, %rd51, 6;
	add.s64 	%rd53, %rd6, %rd52;
	add.s64 	%rd54, %rd53, 263600;
	mov.u16 	%rs5, 48;
	st.u8 	[%rd53+263640], %rs5;
	st.u16 	[%rd53+263642], %r1;
	mov.u64 	%rd55, 1;
	st.u64 	[%rd53+263648], %rd55;
	st.u64 	[%rd53+263656], %rd6;
	ld.u64 	%rd56, [%rd50];
	shl.b64 	%rd57, %rd51, 3;
	add.s64 	%rd58, %rd56, %rd57;
	st.u64 	[%rd58+329136], %rd54;
	setp.eq.s16 	%p8, %rs2, 0;
	and.b32  	%r23, %r1, 31;
	setp.ne.s32 	%p9, %r23, 0;
	or.pred  	%p10, %p8, %p9;
	@%p10 bra 	LBB4_18;
	bra.uni 	LBB4_12;
LBB4_12:
	shr.u32 	%r3, %r1, 5;
	and.b32  	%r24, %r1, 992;
	setp.ne.s32 	%p11, %r24, 992;
	@%p11 bra 	LBB4_15;
	bra.uni 	LBB4_13;
LBB4_13:
	add.s64 	%rd7, %rd6, 263312;
	add.s64 	%rd8, %rd6, 263336;
	ld.u64 	%rd67, [%rd6+263336];
	add.s64 	%rd9, %rd6, 263600;
	setp.eq.s64 	%p13, %rd67, %rd9;
	mov.u64 	%rd66, 0;
	mov.u64 	%rd76, %rd66;
	@%p13 bra 	LBB4_17;
	bra.uni 	LBB4_14;
LBB4_14:
	st.u64 	[%rd8], %rd9;
	mov.u64 	%rd68, 0;
	st.u64 	[%rd7], %rd68;
	st.u64 	[%rd6+263320], %rd68;
	st.u64 	[%rd6+263328], %rd68;
	mov.u64 	%rd10, %rd7;
	mov.u64 	%rd76, %rd10;
	bra.uni 	LBB4_17;
LBB4_15:
	cvt.u64.u32 	%rd11, %r3;
	mul.lo.s64 	%rd60, %rd11, 8224;
	add.s64 	%rd61, %rd6, %rd60;
	add.s64 	%rd12, %rd61, 144;
	add.s64 	%rd13, %rd61, 168;
	ld.u64 	%rd62, [%rd61+168];
	add.s64 	%rd14, %rd61, 8368;
	setp.eq.s64 	%p12, %rd62, %rd14;
	mov.u64 	%rd59, 0;
	mov.u64 	%rd76, %rd59;
	@%p12 bra 	LBB4_17;
	bra.uni 	LBB4_16;
LBB4_16:
	mul.lo.s64 	%rd63, %rd11, 8224;
	add.s64 	%rd64, %rd6, %rd63;
	mov.u64 	%rd15, %rd12;
	st.u64 	[%rd13], %rd14;
	mov.u64 	%rd65, 0;
	st.u64 	[%rd12], %rd65;
	st.u64 	[%rd64+152], %rd65;
	st.u64 	[%rd64+160], %rd65;
	mov.u64 	%rd76, %rd15;
	bra.uni 	LBB4_17;
LBB4_17:
	mov.u64 	%rd16, %rd76;
	cvt.u64.u32 	%rd69, %r3;
	mov.u64 	%rd70, DataSharingState;
	cvta.shared.u64 	%rd71, %rd70;
	shl.b64 	%rd72, %rd69, 3;
	add.s64 	%rd73, %rd71, %rd72;
	st.u64 	[%rd73], %rd16;
	add.s64 	%rd74, %rd16, 32;
	st.u64 	[%rd73+256], %rd74;
	bra.uni 	LBB4_18;
LBB4_18:
	ret;

}
.func  (.param .b32 func_retval0) _ZL9atomicAddPjj7(
	.param .b64 _ZL9atomicAddPjj7_param_0,
	.param .b32 _ZL9atomicAddPjj7_param_1
)
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<2>;

	ld.param.u32 	%r1, [_ZL9atomicAddPjj7_param_1];
	ld.param.u64 	%rd1, [_ZL9atomicAddPjj7_param_0];
	atom.add.u32 	%r2, [%rd1], %r1;
	st.param.b32 	[func_retval0+0], %r2;
	ret;

}
.func  (.param .b64 func_retval0) _ZL9atomicAddPyy8(
	.param .b64 _ZL9atomicAddPyy8_param_0
)
{
	.reg .b64 	%rd<3>;

	ld.param.u64 	%rd1, [_ZL9atomicAddPyy8_param_0];
	atom.or.b64 	%rd2, [%rd1], 0;
	st.param.b64 	[func_retval0+0], %rd2;
	ret;

}
.func _ZL10atomicExchPjj9(
	.param .b64 _ZL10atomicExchPjj9_param_0,
	.param .b32 _ZL10atomicExchPjj9_param_1
)
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<2>;

	ld.param.u32 	%r1, [_ZL10atomicExchPjj9_param_1];
	ld.param.u64 	%rd1, [_ZL10atomicExchPjj9_param_0];
	atom.exch.b32 	%r2, [%rd1], %r1;
	ret;

}
.func __kmpc_spmd_kernel_deinit_v2(
	.param .b32 __kmpc_spmd_kernel_deinit_v2_param_0
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<19>;

	ld.param.u16 	%rs1, [__kmpc_spmd_kernel_deinit_v2_param_0];
	setp.eq.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB8_5;
	bra.uni 	LBB8_1;
LBB8_1:
	bar.sync 	0;
	mov.u32 	%r2, %tid.x;
	setp.ne.s32 	%p2, %r2, 0;
	@%p2 bra 	LBB8_5;
	bra.uni 	LBB8_2;
LBB8_2:
	mov.u64 	%rd5, usedSlotIdx;
	cvta.shared.u64 	%rd6, %rd5;
	ld.s32 	%rd7, [%rd6];
	mul.lo.s64 	%rd8, %rd7, 12040592;
	mov.u64 	%rd9, omptarget_nvptx_device_State;
	add.s64 	%rd10, %rd9, %rd8;
	cvta.global.u64 	%rd1, %rd10;
	mov.u64 	%rd11, omptarget_nvptx_threadPrivateContext;
	cvta.shared.u64 	%rd12, %rd11;
	ld.u64 	%rd2, [%rd12];
	add.s64 	%rd13, %rd1, 12040580;
	mov.u32 	%r3, 1;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r3;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL9atomicAddPjj7, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 11
	and.b32  	%r6, %r4, 31;
	shr.u32 	%r7, %r4, 4;
	or.b32  	%r1, %r7, 1;
	cvt.u64.u32 	%rd3, %r6;
	shl.b64 	%rd14, %rd3, 2;
	add.s64 	%rd15, %rd1, %rd14;
	add.s64 	%rd4, %rd15, 12040452;
	bra.uni 	LBB8_3;
LBB8_3:
	mov.u32 	%r8, 0;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r8;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL9atomicAddPjj7, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r9, [retval0+0];
	} // callseq 12
	setp.ne.s32 	%p3, %r9, %r1;
	@%p3 bra 	LBB8_3;
	bra.uni 	LBB8_4;
LBB8_4:
	shl.b64 	%rd16, %rd3, 3;
	add.s64 	%rd17, %rd1, %rd16;
	add.s64 	%rd18, %rd17, 12040192;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd18;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd2;
	call.uni 
	_ZL10atomicExchPyy, 
	(
	param0, 
	param1
	);
	} // callseq 13
	add.s32 	%r11, %r1, 1;
	and.b32  	%r12, %r11, 33554430;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r12;
	call.uni 
	_ZL10atomicExchPjj9, 
	(
	param0, 
	param1
	);
	} // callseq 14
	bra.uni 	LBB8_5;
LBB8_5:
	ret;

}
.func _ZL10atomicExchPyy(
	.param .b64 _ZL10atomicExchPyy_param_0,
	.param .b64 _ZL10atomicExchPyy_param_1
)
{
	.reg .b64 	%rd<4>;

	ld.param.u64 	%rd2, [_ZL10atomicExchPyy_param_1];
	ld.param.u64 	%rd1, [_ZL10atomicExchPyy_param_0];
	atom.exch.b64 	%rd3, [%rd1], %rd2;
	ret;

}
.func  (.param .b32 func_retval0) __kmpc_global_thread_num(
	.param .b64 __kmpc_global_thread_num_param_0
)
{
	.reg .pred 	%p<27>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<36>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [__kmpc_global_thread_num_param_0];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	LBB10_6;
	bra.uni 	LBB10_1;
LBB10_1:
	ld.u32 	%r1, [%rd1+8];
	and.b32  	%r14, %r1, 1;
	setp.eq.b32 	%p5, %r14, 1;
	mov.pred 	%p6, 0;
	xor.pred  	%p7, %p5, %p6;
	not.pred 	%p8, %p7;
	@%p8 bra 	LBB10_3;
	bra.uni 	LBB10_2;
LBB10_2:
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r32, %r2;
	bra.uni 	LBB10_8;
LBB10_3:
	and.b32  	%r15, %r1, 2;
	setp.ne.s32 	%p9, %r15, 0;
	@%p9 bra 	LBB10_5;
	bra.uni 	LBB10_4;
LBB10_4:
	mov.u32 	%r3, %tid.x;
	mov.u32 	%r31, %r3;
	bra.uni 	LBB10_7;
LBB10_5:
	mov.u64 	%rd2, execution_param;
	cvta.shared.u64 	%rd3, %rd2;
	ld.u32 	%r16, [%rd3];
	and.b32  	%r17, %r16, 1;
	setp.eq.b32 	%p10, %r17, 1;
	mov.pred 	%p11, 0;
	xor.pred  	%p12, %p10, %p11;
	not.pred 	%p13, %p12;
	mov.u32 	%r4, %tid.x;
	mov.u32 	%r31, %r4;
	mov.u32 	%r32, %r4;
	@%p13 bra 	LBB10_7;
	bra.uni 	LBB10_8;
LBB10_6:
	mov.u64 	%rd4, execution_param;
	cvta.shared.u64 	%rd5, %rd4;
	ld.u32 	%r18, [%rd5];
	and.b32  	%r19, %r18, 1;
	setp.eq.b32 	%p14, %r19, 1;
	mov.pred 	%p15, 0;
	xor.pred  	%p16, %p14, %p15;
	mov.u32 	%r5, %tid.x;
	mov.u32 	%r31, %r5;
	mov.u32 	%r32, %r5;
	@%p16 bra 	LBB10_8;
	bra.uni 	LBB10_7;
LBB10_7:
	mov.u32 	%r6, %r31;
	mov.u32 	%r21, %ntid.x;
	add.s32 	%r22, %r21, -1;
	and.b32  	%r23, %r22, -32;
	setp.ge.s32 	%p17, %r6, %r23;
	mov.u32 	%r20, 0;
	mov.u32 	%r32, %r6;
	mov.u32 	%r33, %r6;
	mov.u32 	%r34, %r20;
	@%p17 bra 	LBB10_9;
	bra.uni 	LBB10_8;
LBB10_8:
	mov.u32 	%r7, %r32;
	mov.u32 	%r33, %r7;
	mov.u32 	%r34, %r7;
	bra.uni 	LBB10_9;
LBB10_9:
	mov.u32 	%r9, %r34;
	mov.u32 	%r8, %r33;
	@!%p1 bra 	LBB10_11;
	bra.uni 	LBB10_10;
LBB10_10:
	mov.u64 	%rd8, execution_param;
	cvta.shared.u64 	%rd9, %rd8;
	ld.u32 	%r28, [%rd9];
	and.b32  	%r29, %r28, 1;
	setp.eq.b32 	%p2, %r29, 1;
	mov.pred 	%p26, %p2;
	bra.uni 	LBB10_14;
LBB10_11:
	ld.u32 	%r10, [%rd1+8];
	and.b32  	%r24, %r10, 1;
	setp.eq.b32 	%p19, %r24, 1;
	mov.pred 	%p20, 0;
	xor.pred  	%p21, %p19, %p20;
	mov.pred 	%p18, -1;
	mov.pred 	%p26, %p18;
	@%p21 bra 	LBB10_14;
	bra.uni 	LBB10_12;
LBB10_12:
	and.b32  	%r25, %r10, 2;
	setp.eq.s32 	%p23, %r25, 0;
	mov.pred 	%p22, 0;
	mov.pred 	%p26, %p22;
	@%p23 bra 	LBB10_14;
	bra.uni 	LBB10_13;
LBB10_13:
	mov.u64 	%rd6, execution_param;
	cvta.shared.u64 	%rd7, %rd6;
	ld.u32 	%r26, [%rd7];
	and.b32  	%r27, %r26, 1;
	setp.eq.b32 	%p3, %r27, 1;
	mov.pred 	%p26, %p3;
	bra.uni 	LBB10_14;
LBB10_14:
	mov.pred 	%p4, %p26;
	shr.u32 	%r30, %r8, 5;
	cvt.u64.u32 	%rd10, %r30;
	mov.u64 	%rd11, parallelLevel;
	add.s64 	%rd12, %rd11, %rd10;
	cvta.shared.u64 	%rd13, %rd12;
	ld.u8 	%rs1, [%rd13];
	and.b16  	%rs2, %rs1, 126;
	setp.ne.s16 	%p24, %rs2, 0;
	or.pred  	%p25, %p4, %p24;
	selp.b32 	%r11, 0, %r8, %p24;
	mov.u32 	%r35, %r11;
	@%p25 bra 	LBB10_16;
	bra.uni 	LBB10_15;
LBB10_15:
	mov.u64 	%rd14, omptarget_nvptx_threadPrivateContext;
	cvta.shared.u64 	%rd15, %rd14;
	ld.u64 	%rd16, [%rd15];
	cvt.s64.s32 	%rd17, %r9;
	shl.b64 	%rd18, %rd17, 3;
	add.s64 	%rd19, %rd16, %rd18;
	ld.u64 	%rd20, [%rd19+329136];
	ld.u16 	%r12, [%rd20+42];
	mov.u32 	%r35, %r12;
	bra.uni 	LBB10_16;
LBB10_16:
	mov.u32 	%r13, %r35;
	st.param.b32 	[func_retval0+0], %r13;
	ret;

}

